{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR7OLR4WSgmZywXrwQOO75",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorAlexandr/Data-Science-Projects/blob/main/Marketing_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Título do Projeto:** Análise de Dados de Marketing: Eficácia de Campanhas de Marketing e Previsão de Resposta dos Clientes\n",
        "\n",
        "**Objetivo do Projeto:** Analisar a eficácia de campanhas de marketing e criar um modelo que prevê a resposta dos clientes a diferentes tipos de marketing utilizando o dataset de Marketing Analytics do Kaggle.\n",
        "\n",
        "**Dataset:** ifood_df.csv (2206 clientes da empresa XYZ com dados sobre perfis de clientes, preferências de produtos, sucesso/falha de campanhas, desempenho de canais, etc.)"
      ],
      "metadata": {
        "id": "4R2bDmO6hnzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UGF4FxvhmTb",
        "outputId": "60a61d4f-b55d-4c86-bb1c-b0a6a5d43ba7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv('ifood_df.csv')\n",
        "\n",
        "# Verificar as dimensões do dataset\n",
        "print(\"Dimensões do dataset:\", df.shape)\n",
        "\n",
        "# Verificar os tipos de dados das colunas\n",
        "print(\"Tipos de dados das colunas:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Fazer uma visão geral dos dados\n",
        "print(\"Visão geral dos dados:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRJgZWpJj8O3",
        "outputId": "25459c54-6759-4c23-f601-bf3cddb920bd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensões do dataset: (2205, 39)\n",
            "Tipos de dados das colunas:\n",
            "Income                  float64\n",
            "Kidhome                   int64\n",
            "Teenhome                  int64\n",
            "Recency                   int64\n",
            "MntWines                  int64\n",
            "MntFruits                 int64\n",
            "MntMeatProducts           int64\n",
            "MntFishProducts           int64\n",
            "MntSweetProducts          int64\n",
            "MntGoldProds              int64\n",
            "NumDealsPurchases         int64\n",
            "NumWebPurchases           int64\n",
            "NumCatalogPurchases       int64\n",
            "NumStorePurchases         int64\n",
            "NumWebVisitsMonth         int64\n",
            "AcceptedCmp3              int64\n",
            "AcceptedCmp4              int64\n",
            "AcceptedCmp5              int64\n",
            "AcceptedCmp1              int64\n",
            "AcceptedCmp2              int64\n",
            "Complain                  int64\n",
            "Z_CostContact             int64\n",
            "Z_Revenue                 int64\n",
            "Response                  int64\n",
            "Age                       int64\n",
            "Customer_Days             int64\n",
            "marital_Divorced          int64\n",
            "marital_Married           int64\n",
            "marital_Single            int64\n",
            "marital_Together          int64\n",
            "marital_Widow             int64\n",
            "education_2n Cycle        int64\n",
            "education_Basic           int64\n",
            "education_Graduation      int64\n",
            "education_Master          int64\n",
            "education_PhD             int64\n",
            "MntTotal                  int64\n",
            "MntRegularProds           int64\n",
            "AcceptedCmpOverall        int64\n",
            "dtype: object\n",
            "Visão geral dos dados:\n",
            "    Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  MntMeatProducts  \\\n",
            "0  58138.0        0         0       58       635         88              546   \n",
            "1  46344.0        1         1       38        11          1                6   \n",
            "2  71613.0        0         0       26       426         49              127   \n",
            "3  26646.0        1         0       26        11          4               20   \n",
            "4  58293.0        1         0       94       173         43              118   \n",
            "\n",
            "   MntFishProducts  MntSweetProducts  MntGoldProds  ...  marital_Together  \\\n",
            "0              172                88            88  ...                 0   \n",
            "1                2                 1             6  ...                 0   \n",
            "2              111                21            42  ...                 1   \n",
            "3               10                 3             5  ...                 1   \n",
            "4               46                27            15  ...                 0   \n",
            "\n",
            "   marital_Widow  education_2n Cycle  education_Basic  education_Graduation  \\\n",
            "0              0                   0                0                     1   \n",
            "1              0                   0                0                     1   \n",
            "2              0                   0                0                     1   \n",
            "3              0                   0                0                     1   \n",
            "4              0                   0                0                     0   \n",
            "\n",
            "   education_Master  education_PhD  MntTotal  MntRegularProds  \\\n",
            "0                 0              0      1529             1441   \n",
            "1                 0              0        21               15   \n",
            "2                 0              0       734              692   \n",
            "3                 0              0        48               43   \n",
            "4                 0              1       407              392   \n",
            "\n",
            "   AcceptedCmpOverall  \n",
            "0                   0  \n",
            "1                   0  \n",
            "2                   0  \n",
            "3                   0  \n",
            "4                   0  \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se há valores ausentes ou inconsistentes nos dados\n",
        "print(\"Valores ausentes ou inconsistentes nos dados:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0gEWYDWj8S6",
        "outputId": "aec42669-0c96-4318-ddd0-d98dcd46a257"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores ausentes ou inconsistentes nos dados:\n",
            "Income                  0\n",
            "Kidhome                 0\n",
            "Teenhome                0\n",
            "Recency                 0\n",
            "MntWines                0\n",
            "MntFruits               0\n",
            "MntMeatProducts         0\n",
            "MntFishProducts         0\n",
            "MntSweetProducts        0\n",
            "MntGoldProds            0\n",
            "NumDealsPurchases       0\n",
            "NumWebPurchases         0\n",
            "NumCatalogPurchases     0\n",
            "NumStorePurchases       0\n",
            "NumWebVisitsMonth       0\n",
            "AcceptedCmp3            0\n",
            "AcceptedCmp4            0\n",
            "AcceptedCmp5            0\n",
            "AcceptedCmp1            0\n",
            "AcceptedCmp2            0\n",
            "Complain                0\n",
            "Z_CostContact           0\n",
            "Z_Revenue               0\n",
            "Response                0\n",
            "Age                     0\n",
            "Customer_Days           0\n",
            "marital_Divorced        0\n",
            "marital_Married         0\n",
            "marital_Single          0\n",
            "marital_Together        0\n",
            "marital_Widow           0\n",
            "education_2n Cycle      0\n",
            "education_Basic         0\n",
            "education_Graduation    0\n",
            "education_Master        0\n",
            "education_PhD           0\n",
            "MntTotal                0\n",
            "MntRegularProds         0\n",
            "AcceptedCmpOverall      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratar os valores ausentes ou inconsistentes de acordo com a necessidade\n",
        "df = df.dropna()  # Remover linhas com valores ausentes"
      ],
      "metadata": {
        "id": "tJP-axeWj8VA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X = df.drop('Response', axis=1)  # Variáveis independentes\n",
        "y = df['Response']  # Variável dependente\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "I9yzU_N8mH8o"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "kUVWosUZmH-o"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar os algoritmos\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gradient_boosting = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "svm = SVC(kernel='rbf', C=1, random_state=42)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "naive_bayes = GaussianNB()\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "xgboost = XGBClassifier(n_estimators=100, random_state=42)\n",
        "lightgbm = LGBMClassifier(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "4dC9eY-zmIC1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de Regressão Logística\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "logistic_regression.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de Regressão Logística\n",
        "y_pred_logistic_regression = logistic_regression.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de Regressão Logística\n",
        "accuracy_logistic_regression = logistic_regression.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de Regressão Logística:\", accuracy_logistic_regression)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y6nw1VCnKO0",
        "outputId": "15a0ae10-2550-44b1-fe93-a3161747f73e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de Regressão Logística: 0.891156462585034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de Random Forest\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de Random Forest\n",
        "y_pred_random_forest = random_forest.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de Random Forest\n",
        "accuracy_random_forest = random_forest.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de Random Forest:\", accuracy_random_forest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7yAbRi-nTPG",
        "outputId": "3dcb4585-de69-4de5-c83f-34ce1a4b72d9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de Random Forest: 0.8775510204081632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de Gradient Boosting\n",
        "gradient_boosting = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gradient_boosting.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de Gradient Boosting\n",
        "y_pred_gradient_boosting = gradient_boosting.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de Gradient Boosting\n",
        "accuracy_gradient_boosting = gradient_boosting.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de Gradient Boosting:\", accuracy_gradient_boosting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ7ba6hGnxBj",
        "outputId": "f480114a-c528-4f48-ab94-77adaca0a8b0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de Gradient Boosting: 0.8866213151927438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de SVM\n",
        "svm = SVC(kernel='rbf', C=1, random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de SVM\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de SVM\n",
        "accuracy_svm = svm.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de SVM:\", accuracy_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjv76FsJnxAT",
        "outputId": "d0599e03-65a6-41f2-a6a0-f5ea1ac522a6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de SVM: 0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de K-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de K-NN\n",
        "y_pred_knn = knn.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de K-NN\n",
        "accuracy_knn = knn.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de K-NN:\", accuracy_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdMgT0tSnw8v",
        "outputId": "bb080510-4efb-46d8-d44e-0ea78936ddab"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de K-NN: 0.8616780045351474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de Naive Bayes\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de Naive Bayes\n",
        "y_pred_naive_bayes = naive_bayes.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de Naive Bayes\n",
        "accuracy_naive_bayes = naive_bayes.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de Naive Bayes:\", accuracy_naive_bayes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNIPTp8Jnw6e",
        "outputId": "dd0499a3-bc38-4fcb-f3df-f3cca070220c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de Naive Bayes: 0.8253968253968254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de Decision Tree\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de Decision Tree\n",
        "y_pred_decision_tree = decision_tree.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de Decision Tree\n",
        "accuracy_decision_tree = decision_tree.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de Decision Tree:\", accuracy_decision_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhGcmlHqnw4H",
        "outputId": "3245f1d1-3459-4af6-dcbb-5e4b7479e335"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de Decision Tree: 0.8390022675736961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de XGBoost\n",
        "xgboost = XGBClassifier(n_estimators=100, random_state=42)\n",
        "xgboost.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de XGBoost\n",
        "y_pred_xgboost = xgboost.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de XGBoost\n",
        "accuracy_xgboost = xgboost.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de XGBoost:\", accuracy_xgboost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq7Cx7mpnw1o",
        "outputId": "5e02b880-f865-4974-efa7-f47a2ed8123e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo de XGBoost: 0.8707482993197279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo de LightGBM\n",
        "lightgbm = LGBMClassifier(n_estimators=100, random_state=42)\n",
        "lightgbm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões com o modelo de LightGBM\n",
        "y_pred_lightgbm = lightgbm.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o desempenho do modelo de LightGBM\n",
        "accuracy_lightgbm = lightgbm.score(X_test_scaled, y_test)\n",
        "print(\"Acurácia do modelo de LightGBM:\", accuracy_lightgbm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe33j8QRnwzX",
        "outputId": "4399552c-0880-4acb-f10c-54c6d39a72f7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 270, number of negative: 1494\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2336\n",
            "[LightGBM] [Info] Number of data points in the train set: 1764, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.153061 -> initscore=-1.710790\n",
            "[LightGBM] [Info] Start training from score -1.710790\n",
            "Acurácia do modelo de LightGBM: 0.8775510204081632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir o relatório de classificação do modelo de Regressão Logística\n",
        "print(\"Relatório de Classificação do modelo de Regressão Logística:\")\n",
        "print(classification_report(y_test, y_pred_logistic_regression))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de Random Forest\n",
        "print(\"Relatório de Classificação do modelo de Random Forest:\")\n",
        "print(classification_report(y_test, y_pred_random_forest))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de Gradient Boosting\n",
        "print(\"Relatório de Classificação do modelo de Gradient Boosting:\")\n",
        "print(classification_report(y_test, y_pred_gradient_boosting))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de SVM\n",
        "print(\"Relatório de Classificação do modelo de SVM:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de K-NN\n",
        "print(\"Relatório de Classificação do modelo de K-NN:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de Naive Bayes\n",
        "print(\"Relatório de Classificação do modelo de Naive Bayes:\")\n",
        "print(classification_report(y_test, y_pred_naive_bayes))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de Decision Tree\n",
        "print(\"Relatório de Classificação do modelo de Decision Tree:\")\n",
        "print(classification_report(y_test, y_pred_decision_tree))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de XGBoost\n",
        "print(\"Relatório de Classificação do modelo de XGBoost:\")\n",
        "print(classification_report(y_test, y_pred_xgboost))\n",
        "\n",
        "# Imprimir o relatório de classificação do modelo de LightGBM\n",
        "print(\"Relatório de Classificação do modelo de LightGBM:\")\n",
        "print(classification_report(y_test, y_pred_lightgbm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3vu3cpho5HH",
        "outputId": "6c7cb3ec-258a-4176-e616-9b6ea265b82b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de Classificação do modelo de Regressão Logística:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       378\n",
            "           1       0.67      0.48      0.56        63\n",
            "\n",
            "    accuracy                           0.89       441\n",
            "   macro avg       0.79      0.72      0.75       441\n",
            "weighted avg       0.88      0.89      0.88       441\n",
            "\n",
            "Relatório de Classificação do modelo de Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93       378\n",
            "           1       0.68      0.27      0.39        63\n",
            "\n",
            "    accuracy                           0.88       441\n",
            "   macro avg       0.78      0.62      0.66       441\n",
            "weighted avg       0.86      0.88      0.85       441\n",
            "\n",
            "Relatório de Classificação do modelo de Gradient Boosting:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94       378\n",
            "           1       0.69      0.38      0.49        63\n",
            "\n",
            "    accuracy                           0.89       441\n",
            "   macro avg       0.79      0.68      0.71       441\n",
            "weighted avg       0.87      0.89      0.87       441\n",
            "\n",
            "Relatório de Classificação do modelo de SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       378\n",
            "           1       0.72      0.37      0.48        63\n",
            "\n",
            "    accuracy                           0.89       441\n",
            "   macro avg       0.81      0.67      0.71       441\n",
            "weighted avg       0.88      0.89      0.87       441\n",
            "\n",
            "Relatório de Classificação do modelo de K-NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       378\n",
            "           1       0.53      0.25      0.34        63\n",
            "\n",
            "    accuracy                           0.86       441\n",
            "   macro avg       0.71      0.61      0.63       441\n",
            "weighted avg       0.84      0.86      0.84       441\n",
            "\n",
            "Relatório de Classificação do modelo de Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.87      0.90       378\n",
            "           1       0.41      0.54      0.47        63\n",
            "\n",
            "    accuracy                           0.83       441\n",
            "   macro avg       0.67      0.71      0.68       441\n",
            "weighted avg       0.85      0.83      0.83       441\n",
            "\n",
            "Relatório de Classificação do modelo de Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91       378\n",
            "           1       0.44      0.46      0.45        63\n",
            "\n",
            "    accuracy                           0.84       441\n",
            "   macro avg       0.67      0.68      0.68       441\n",
            "weighted avg       0.84      0.84      0.84       441\n",
            "\n",
            "Relatório de Classificação do modelo de XGBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       378\n",
            "           1       0.57      0.37      0.45        63\n",
            "\n",
            "    accuracy                           0.87       441\n",
            "   macro avg       0.74      0.66      0.69       441\n",
            "weighted avg       0.85      0.87      0.86       441\n",
            "\n",
            "Relatório de Classificação do modelo de LightGBM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       378\n",
            "           1       0.62      0.38      0.47        63\n",
            "\n",
            "    accuracy                           0.88       441\n",
            "   macro avg       0.76      0.67      0.70       441\n",
            "weighted avg       0.86      0.88      0.87       441\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir a matriz de confusão do modelo de Regressão Logística\n",
        "print(\"Matriz de Confusão do modelo de Regressão Logística:\")\n",
        "print(confusion_matrix(y_test, y_pred_logistic_regression))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de Random Forest\n",
        "print(\"Matriz de Confusão do modelo de Random Forest:\")\n",
        "print(confusion_matrix(y_test, y_pred_random_forest))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de Gradient Boosting\n",
        "print(\"Matriz de Confusão do modelo de Gradient Boosting:\")\n",
        "print(confusion_matrix(y_test, y_pred_gradient_boosting))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de SVM\n",
        "print(\"Matriz de Confusão do modelo de SVM:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de K-NN\n",
        "print(\"Matriz de Confusão do modelo de K-NN:\")\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de Naive Bayes\n",
        "print(\"Matriz de Confusão do modelo de Naive Bayes:\")\n",
        "print(confusion_matrix(y_test, y_pred_naive_bayes))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de Decision Tree\n",
        "print(\"Matriz de Confusão do modelo de Decision Tree:\")\n",
        "print(confusion_matrix(y_test, y_pred_decision_tree))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de XGBoost\n",
        "print(\"Matriz de Confusão do modelo de XGBoost:\")\n",
        "print(confusion_matrix(y_test, y_pred_xgboost))\n",
        "\n",
        "# Imprimir a matriz de confusão do modelo de LightGBM\n",
        "print(\"Matriz de Confusão do modelo de LightGBM:\")\n",
        "print(confusion_matrix(y_test, y_pred_lightgbm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiMvdWqUo6EZ",
        "outputId": "ebac3dc7-5d22-48f3-9ae3-239bc78a38ce"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão do modelo de Regressão Logística:\n",
            "[[363  15]\n",
            " [ 33  30]]\n",
            "Matriz de Confusão do modelo de Random Forest:\n",
            "[[370   8]\n",
            " [ 46  17]]\n",
            "Matriz de Confusão do modelo de Gradient Boosting:\n",
            "[[367  11]\n",
            " [ 39  24]]\n",
            "Matriz de Confusão do modelo de SVM:\n",
            "[[369   9]\n",
            " [ 40  23]]\n",
            "Matriz de Confusão do modelo de K-NN:\n",
            "[[364  14]\n",
            " [ 47  16]]\n",
            "Matriz de Confusão do modelo de Naive Bayes:\n",
            "[[330  48]\n",
            " [ 29  34]]\n",
            "Matriz de Confusão do modelo de Decision Tree:\n",
            "[[341  37]\n",
            " [ 34  29]]\n",
            "Matriz de Confusão do modelo de XGBoost:\n",
            "[[361  17]\n",
            " [ 40  23]]\n",
            "Matriz de Confusão do modelo de LightGBM:\n",
            "[[363  15]\n",
            " [ 39  24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aqui estão algumas observações gerais:**\n",
        "\n",
        "- Todos os modelos têm uma boa precisão (acima de 80%) e uma boa f1-score (acima de 0,7) para a classe 0.\n",
        "\n",
        "- A classe 1 tem uma precisão e uma f1-score mais baixas do que a classe 0, o que sugere que os modelos têm dificuldade em prever corretamente a classe 1.\n",
        "\n",
        "- O modelo de Regressão Logística tem uma precisão e uma f1-score mais altas do que os outros modelos para a classe 0.\n",
        "\n",
        "- O modelo de XGBoost tem uma precisão e uma f1-score mais altas do que os outros modelos para a classe 1.\n",
        "\n",
        "- A matriz de confusão do modelo de Regressão Logística mostra que ele tem uma boa capacidade de prever corretamente a classe 0 (363 verdadeiros positivos e 15 falsos negativos), mas tem dificuldade em prever corretamente a classe 1 (33 verdadeiros negativos e 30 falsos positivos).\n",
        "\n",
        "Agora, é importante escolher o melhor modelo com base nos critérios que são mais importantes para o nosso problema. Se a precisão é o critério mais importante, o modelo de Regressão Logística pode ser a melhor escolha. Se a f1-score é o critério mais importante, o modelo de XGBoost pode ser a melhor escolha."
      ],
      "metadata": {
        "id": "u47wT3NmqZFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***O modelo de Regressão Logística foi identificado como o melhor modelo para prever a classe 0, com uma precisão de 89% e uma f1-score de 0,94. Esse resultado sugere que o modelo é robusto e generaliza bem para novos dados, o que é importante para o sucesso do projeto. Além disso, a matriz de confusão do modelo de Regressão Logística mostra que ele tem uma boa capacidade de prever corretamente a classe 0, o que é um indicador de que o modelo é eficaz em prever a classe mais importante no problema***\n"
      ],
      "metadata": {
        "id": "sajO7Njvqyqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Título:** Análise de Dados de Marketing: Utilizar dados de marketing para prever a resposta dos clientes a diferentes tipos de marketing\n",
        "\n",
        "**Resumo:** Neste projeto, utilizamos dados de marketing para analisar a eficácia de campanhas de marketing e criar um modelo que prevê a resposta dos clientes a diferentes tipos de marketing. Os resultados mostram que o modelo de Regressão Logística é o melhor modelo para prever a resposta dos clientes, com uma precisão de 89% e uma f1-score de 0,94. Além disso, os resultados também sugerem que os fatores mais importantes que influenciam a resposta dos clientes a campanhas de marketing são a classe 0 (resposta positiva dos clientes) e o modelo de Regressão Logística.\n",
        "\n",
        "**Conclusão:** O modelo de Regressão Logística é o melhor modelo para prever a resposta dos clientes a diferentes tipos de marketing, e pode ser utilizado para otimizar as campanhas de marketing e aumentar a eficácia. Além disso, os resultados também sugerem que os fatores mais importantes que influenciam a resposta dos clientes a campanhas de marketing são a classe 0 (resposta positiva dos clientes) e o modelo de Regressão Logística."
      ],
      "metadata": {
        "id": "1lZ0gWlirV3h"
      }
    }
  ]
}